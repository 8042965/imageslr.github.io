---
layout: post
title: 🗂【面试题】技术面试题汇总 🔥
date: 2020/10/3 13:00
permalink: 2020/07/08/tech-interview.html
toc: false
# redirect_to: http://www.github.com
---

<details markdown="1" open style="margin-top: -2rem">
<summary>
<h3 style="display: inline-block; margin: 0;">目录</h3>
</summary>
- [前言](#前言)
- [操作系统](#操作系统)
  - [内核态和用户态](#内核态和用户态)
  - [陷阱、中断、异常、信号](#陷阱中断异常信号)
  - [进程和线程](#进程和线程)
  - [进程的调度](#进程的调度)
  - [线程和进程的通信方式](#线程和进程的通信方式)
  - [锁的类型与实现](#锁的类型与实现)
  - [进程的同步与互斥](#进程的同步与互斥)
  - [死锁的预防、检测、避免、解除](#死锁的预防检测避免解除)
  - [物理内存管理](#物理内存管理)
  - [虚拟内存管理](#虚拟内存管理)
  - [虚拟地址空间的组成部分](#虚拟地址空间的组成部分)
  - [大端法、小端法](#大端法小端法)
  - [缓冲区溢出问题](#缓冲区溢出问题)
  - [进程的内存管理](#进程的内存管理)
  - [I/O 模型](#io-模型)
  - [协程](#协程)
  - [写时复制 Copy-on-write](#写时复制-copy-on-write)
- [计算机网络](#计算机网络)
  - [协议栈](#协议栈)
  - [两台主机间的通信过程](#两台主机间的通信过程)
  - [TCP 如何保证传输的可靠性](#tcp-如何保证传输的可靠性)
  - [TCP 的流量控制和拥塞控制](#tcp-的流量控制和拥塞控制)
  - [TCP 的三次握手和四次挥手](#tcp-的三次握手和四次挥手)
  - [TCP、UDP 对比](#tcpudp-对比)
  - [HTTP 原理](#http-原理)
  - [HTTPS 原理](#https-原理)
  - [DNS 的解析过程](#dns-的解析过程)
  - [IP 原理](#ip-原理)
  - [从输入一个 URL 到页面加载完成的过程](#从输入一个-url-到页面加载完成的过程)
- [数据库](#数据库)
  - [数据库的存储引擎](#数据库的存储引擎)
  - [数据库的索引](#数据库的索引)
  - [数据库的事务](#数据库的事务)
  - [数据库的并发控制](#数据库的并发控制)
  - [数据库分库、分表、主从、读写分离](#数据库分库分表主从读写分离)
  - [数据库的优化方法](#数据库的优化方法)
  - [数据库内连接、外连接的含义](#数据库内连接外连接的含义)
  - [ORM 和原生 SQL 的区别](#orm-和原生-sql-的区别)
  - [Redis 相关](#redis-相关)
- [数据结构](#数据结构)
  - [哈希表](#哈希表)
  - [Map 的实现](#map-的实现)
- [计算机组成原理](#计算机组成原理)
- [多线程编程](#多线程编程)
- [开发与运维](#开发与运维)
  - [Linux 常用命令](#linux-常用命令)
- [分布式](#分布式)
- [网络安全](#网络安全)
- [面经汇总](#面经汇总)
</details>

## 前言

这是我用来准备后端开发校招面试的笔记汇总。这些题目或多或少都在不同公司的面试过程中出现过，因此将其总结起来，可以用作复习阶段的**知识点梳理**，也可以用作面试前的**快速回顾**。

本文采用「题目 - 子问题 - 答案」的形式，答案默认折叠。大部分问题都是简答，可以直接采用。但是深入了解细节，才能应对面试官进一步的问题，因此我也将部分问题整理为单独的文章，之后还会持续更新。

## 操作系统

### 内核态和用户态

- 内核态和用户态的区别
- 什么时候会陷入内核态
- C 访问空指针会不会陷入内核态？

[答案]({% post_url 2020-07-08-user-mode-kernel-mode%})

### 陷阱、中断、异常、信号

- 陷阱、中断、异常、信号的产生来源
- 陷阱、中断、异常、信号的处理流程
- 常见的陷阱、中断、异常、信号有哪些？

[答案]({% post_url 2020-07-10-trap-interrupt-exception%})

### 进程和线程

- 进程与线程的区别
- 为什么需要线程
- 线程的优缺点
- 同一进程中的线程共享与独占的资源
- 线程的实现方式

[答案]({% post_url 2020-07-08-process-thread%})

### 进程的调度

- 进程的状态
- 批处理系统、交互系统的调度算法
- 僵尸进程、孤儿进程、守护进程

[答案]({% post_url 2020-07-08-process-schedule%})

### 线程和进程的通信方式

- 信号、管道、信号量、共享内存、消息队列
- 各种通信方式的原理、适用场景

[答案]({% post_url 2020-02-26-ipc%})

### 锁的类型与实现

- 了解哪些类型的锁？
- 互斥锁的实现方式

<details markdown="1">
<summary>答案</summary>
* 不同类型的锁：互斥锁、读写锁、自旋锁、条件锁。
* Java 中的锁类型：
  * 公平锁/非公平锁
  * 可重入锁
  * 独享锁/共享锁
  * 互斥锁/读写锁
  * 乐观锁/悲观锁
  * 分段锁
  * 偏向锁/轻量级锁/重量级锁
  * 自旋锁
* 互斥锁的实现方式：[答案]({% post_url 2020-09-26-locks%})
</details>

### 进程的同步与互斥

- 临界资源和临界区的概念
- 同步和互斥的概念
- 临界区的管理原则
- 信号量和 P / V 操作
- 一些常见的并发问题
  - 生产者与消费者问题
  - 读者写者问题
  - 浴室洗澡问题
  - 哲学家就餐问题

[答案]({% post_url 2020-09-27-sync-and-mutex%})

### 死锁的预防、检测、避免、解除

- 死锁产生的四个必要条件
- 如何预防、检测、避免、解除死锁？

<details markdown="1">
<summary>答案</summary>

**(1) 死锁产生的四个必要条件**

- **互斥**条件
- **占有且等待**条件：线程占有已经分配给它们的资源（如锁）并且等待其他的资源（也就是说不会*主动*释放）
- **不可抢占**条件（也就是说不会*被动*释放）
- **环路等待**条件：每个进程都在等待下一个进程占有的资源

这四个条件缺少一个就不会有死锁。

**(2) 预防死锁**

预防死锁就是破坏上面四个条件任意一个，但是实现很难：

- 破坏互斥条件：允许某些资源同时被多个进程访问。但是有些资源本身并不具有这种属性，因此这种方案实用性有限
- 破坏占有并等待条件：
  - 实行资源预先分配策略（当一个进程开始运行之前，必须一次性向系统申请它所需要的全部资源，否则不运行）
  - 或者只允许进程在没有占用资源的时候才能申请资源（申请资源前先释放占有的资源）
  - 缺点：很多时候无法预知一个进程所需的全部资源；同时，会降低资源利用率，降低系统的并发性
- 破坏非抢占条件：允许进程强行抢占被其它进程占有的资源。会降低系统性能
- 破坏循环等待条件：对所有资源统一编号，所有进程对资源的请求必须按照序号递增的顺序提出，即只有占有了编号较小的资源才能申请编号较大的资源。这样避免了占有大号资源的进程去申请小号资源，各个进程申请资源的顺序都是从小到大，就不会有环了

**(3) 避免死锁**

允许系统中同时存在四个必要条件，但是每当进程提出资源申请时，系统要分析满足该资源请求后，系统是否会发生死锁，若不会发生则实施分配，否则拒绝分配。银行家算法实现了这个过程。

**(4) 检测死锁**

画出资源分配图，检测是否存在环路。检测环路前要将资源分配图化简，化简的原理是“一个目前占有运行所需的资源的进程，迟早能够执行完成释放资源”。因此，可以从“进程—资源分配图”中找到一个既不阻塞又非孤立的进程，删除所有与该进程相连的有向边，回收资源，使之成为孤立结点，然后将所回收的资源分配给其它进程。循环此过程，直到无法化简。若仍存在环路，则该系统目前处于死锁状态。

检测到死锁后，需要解除死锁。

**(5) 解除死锁**

破坏除了“互斥条件”之外的其他三个条件：

- 回退执行：系统定期对各个进程进行检查，将检查点的有关信息写入文件。死锁时，让某占有必要资源的进程**回退**到取得资源之前的一个检查点，释放的资源分配给一个死锁进程（破坏“占有且等待”）
- 抢占资源：**剥夺**占有进程的资源，**分配**给另外某些进程，直至死锁环路被打破（破坏“不可抢占”）
- 杀掉进程：一次**终止**一个进程，直至消除死锁环路（破坏“循环等待”）

</details>

### 物理内存管理

- 不同的内存分配技术及其优缺点
  - 固定分区法（等长、不等长）
  - 动态分区法
  - 页式内存管理
  - 段式内存管理
  - 段页式内存管理
- 不同的动态分区放置算法及其优缺点

<details markdown="1">
<summary>答案</summary>

**内部碎片和外部碎片：**

- 内部碎片是固定分区法产生的，指被占用分区上未被利用的空间，由于该分区被占用，因此无法被分配使用
- 外部碎片是动态分区法产生的，指被占用分区之间的小空间，虽然可以被使用，但是由于太小而无法被分配

**(1) 不同的内存分配技术及其优缺点**

1. 等长固定分区法：每个分区大小相同，在系统启动时分配好，系统运行期间保持不变；每次给进程分配一整块区域，因此进程的大小必须 ≤ 分区的大小
   - 优点：系统需要维护的管理信息非常少，只要维护一个固定行数的表格，记载分区的使用情况；内存分配算法很简单，有足够大空闲分区就分配，否则就拒绝
   - 缺点：不同进程需要的空间不同，内部碎片多，浪费空间；分区总数固定，限制了并发执行的程序数量
2. 不等长固定分区法：每个分区大小不同，在系统启动时分配好，系统运行期间保持不变；分配时，需要根据进程的大小在空闲分区中选择一个大小合适的分区（优缺点同上）
3. 动态分区法：在系统运行中，根据每个进程需要的空间大小确定分区大小；通过空闲分区链表进行组织
   - 优点：并发执行的程序数量不受限制，只取决于是否有大小合适的内存块可以分配
   - 缺点：管理空闲快的复杂度增加；分配算法的时间开销增加，可能需要遍历多次才能找到合适的内存块
4. 页式内存管理：把固定分区面积缩小，一个进程可使用多个分区；进程被分割成若干块，装入内存中的几个分区中，物理上无需相连，逻辑上通过页表关联。这是一种内存的不连续分配方法
   - 优点：不存在任何外部碎片，只在每个进程的最后一个页框中存在内部碎片
5. 段式内存管理：按照逻辑意义将程序分成若干个段，每个段独立载入到内存的不同区间中
   - 优点：分页不考虑每个页中内容的意义，而分段是按照逻辑关系划分
   - 缺点：每个段必须连续、全部加载到内存中
6. 段页式内存管理：把分段和分页两种方式结合，先把程序按照逻辑意义分成段，然后每个段再分成固定大小的页

参考资料：[段式内存管理 - Edison Zhou](https://www.cnblogs.com/edisonchou/p/5115242.html)

**(2) 不同的动态分区放置算法及其优缺点**

- 最佳适应算法
  - 检查所有空闲分区，选择和新进程申请内存大小最接近的空闲分区
  - 优点：该算法保留大的空闲区
  - 缺点
    - 检查所有空闲分区需要时间
    - 外部碎片多：会留下许多难以利用的，很小的空闲分区，称为外部碎片
    - 可以采用内存紧凑的方法，将被使用的分区都移动到一起，减少外部碎片。但是移动内存中的代码和数据也需要很多时间
- 最差适应算法
  - 每次为进程分配分区时，都选择最大的空闲分区分配
  - 最差适应算法使链表中的结点大小趋于均匀，适用于请求分配的内存大小范围较窄的系统
  - 优点：该算法保留小的空闲区，尽量减少外部碎片的产生
  - 缺点：检查比较所有的空闲区间需要时间；系统中不会存在面积很大的空闲区间，难满足大进程的要求
- 首次适应法
  - 只要发现能用的分区就分配。这种方法目的在于减少查找时间。为适应这种算法，空闲分区表（空闲区链）中的空闲分区要按地址由低到高进行排序。该算法优先使用低址部分空闲区，在低址空间造成许多小的空闲区，在高地址空间保留大的空闲区
  - 优点：可以剩下大的分区
  - 缺点：外部碎片多，集中在低址部分；并且每次查找都是从低址部分开始的，这无疑又会增加查找可用空闲分区时的开销
- 下一个适应法
  - 由于上面的放置算法每次都需要从头检查，有可能浪费很多时间。因此“下一个适应法”就是操作系统记住接下来该检查的空闲分区的位置，给进程分配分区时，系统从记录的分区开始依次向后查找直到碰到能用的分区为止，如果到链表尾还没有找到，就再从头开始
  - 缺点：上面的三个放置算法都是按照分区大小来分配，或是留下大区间（首次适应，最佳适应），或是留下小区间（最差适应）。下一个适应法很难剩下面积很大的区间，会使剩余分区的大小比较平均

</details>

### 虚拟内存管理

- 虚拟内存的思想 / 实现方式
- 暂时不在内存中的数据存在哪里？
- 虚拟地址的映射
  - 页表、页表表项结构
  - 多级页表
  - 倒排页表
  - 散列表
- TLB 的原理
- 缺页中断的处理
- 什么是页面淘汰？
- 不同的淘汰算法及其适用场景

<details markdown="1">
<summary>答案</summary>

**(1) 虚拟内存的思想 / 实现方式**

- 在系统中为每个程序定义一个虚拟地址空间，虚拟地址空间中的地址都是连续的
- 虚拟地址空间被分割成多个块，每块称为一个页或者**页面**
- 物理内存被分成和页面大小相同的多个区域，称作**页框**
- 程序加载时，可将任意一个页面放入内存中的任意一个页框
- CPU 的硬件负责将虚拟地址映射到物理内存中的地址（页面 -> 页框）
- 程序的整个地址空间无需全部载入物理内存，还有部分暂时存储在外存上，需要时再换入内存
- 如果程序引用到一部分不在物理内存中的虚拟地址时，会发生**缺页中断**，由操作系统负责将缺失的页面加载入页框中，并重新执行失败的指令

![](/media/16013686415116.jpg)

**(2) 暂时不在内存中的数据存在哪里？**

存储在交换分区（swap）中。当内存不足的时候，操作系统先把内存中暂时不用的数据，存到硬盘的交换空间，释放内存空间。详见 [Swap - ArchWiki](<https://wiki.archlinux.org/index.php/Swap_(%E7%AE%80%E4%BD%93%E4%B8%AD%E6%96%87)>) 。

**(3) 虚拟地址的映射**

页表：每个进程有一个页表，描述该进程每个页面对应的页框号，以及该页面是否已经被载入内存（“在/不在”位）。以下是一个进程的页表和地址映射过程的示意图：

![](/media/16013673021620.jpg)

- 一个完整的页表表项包含以下内容：
  - 页框号
  - 存在位：页面是否在内存中：
  - 访问位：页面是否已被访问，影响页面淘汰选择
  - 修改位：页面是否被修改，修改过的页面需要重新写回外存
  - ...
  - _页面号：在页表中的下标，并不是一项真的内容_

进程在运行时，需要将页表放在内存中。但在虚拟地址空间很大的情况下，会被分成很多个页面，那么进程的页表将占据很大的内存空间，甚至无法全部载入内存。

有一些针对大内存的页表实现方式：

- 多级页表：将页表进一步分页，页目录表相当于“页表的页表”，记录每个内层页表存放在哪个页框中；内层页表依然记录进程的每个页面存放在哪个页框中。以下是一个多级页表的示意图：  
  ![](/media/16013681214932.jpg)
- 倒排页表：不再为每个进程记录页面到页框的映射，而是记录每个页框对应的 `(进程号, 页面号)` 二元组。整个操作系统只需要一个倒排页表，节省了大量空间。但是它必须遍历整个页表才能找到某个表项，无法将页面号当作索引直接找到页框号。  
  ![](/media/16013683017475.jpg){: width="400px"}
- 散列表：为了节省页表空间，同时加速查找过程，可以将当前进程的所有「在内存中」的页面建立一张散列表。用每个页面的虚拟地址来散列，相同散列值的元素会被链接到一起，每个元素包含三项内容：页面号、页框号、指向链表中下一个元素的指针。  
  ![](/media/16013683206787.jpg){: width="400px"}

**(4) TLB 的原理**

现代操作系统中，页表的个数是很多的，而每次执行语句时都需要先查找页表，将虚拟地址转换为物理内存地址。这部分切换的时间开销是很大的。因此，解决方案是为计算机设置一个小型的硬件设备 TLB。

转换检测缓冲区（TLB，translation-lookaside buffer），是 MMU（内存管理单元）的一部分。它提供一个缓冲区，记录虚拟**页面号**到物理**页框号**的映射，这样可以在 O(1) 的时间里直接将虚拟页面映射到物理页框，不需要访问页表，从而节省时间。

工作流程：如果页面号在 TLB 中，得到页框号，访问内存；否则，从内存中的页表中得到页框号，将其存入 TLB，访问内存。

TLB 基于局部性原理实现：

- 空间局部性：如果程序访问了地址 `x`，那么很有可能访问 `x` 附近的地址
- 时间局部性：如果程序访问了地址 `x`，很可能立刻又访问 `x`

**(5) 缺页中断的处理**

应用程序访问未加载到内存中的页面时，会引起缺页中断。操作系统回将缺失的页面加载入页框中，然后重新执行引起异常的指令。

缺页中断更准确地说，应当是“缺页异常（page fault）”。异常执行当前指令产生的错误情况，中断则是外部硬件产生的事件。详见[陷阱、中断、异常、信号]({% post_url 2020-07-10-trap-interrupt-exception%}#exception)。

**(6) 页面淘汰**

当内存空间已被占满而又要调入新的页面时，必须将已在内存中的某个页面淘汰掉。如果被淘汰的页面曾被修改过，还要将此页写回到外存，再换进新的页面。这一过程称为**页面淘汰**。

如果某个页面频繁的被“调入-淘汰-调入-淘汰”，这种现象称为抖动。抖动导致系统将大部分时间花在了页面的置换上，因此在淘汰时，要选择今后不会或者最近不会用到的内容，以减少抖动。

**(7) 不同的淘汰算法及其适用场景**

根据具体的应用场景，选择合适的淘汰算法。除了操作系统的页面置换，redis 中也经常用到各种内存淘汰算法，往往需要结合具体业务场景来选择。

以下是几种常见的淘汰算法：

1. 最佳置换算法 / 最优策略（OPT）：选择以后再也不会用到的页面淘汰；如果都会用到，就选择那些再次使用的时间距离现在最远的页面淘汰。这是一种理想情况下的页面置换算法，实际上不可能实现。可以作为评测其他淘汰策略的标准。
2. 先进先出法（FIFO）：直接换出最早装入的页面。
   - 优点：简单
   - 缺点：性能不是很好，因为它淘汰的可能是常用的页面
   - 适用场景：数据只用一次，将来不太可能使用；[redis] 对数据时效性有要求（越旧的缓存越先被淘汰）
3. 第二次机会置换法（SCR：Second Chance Replacement）：对 FIFO 算法的改进，每个页面访问 2 次后再淘汰。具体实现上，设置页面访问位，每次检查队首的页面访问位：如果该位为 0，淘汰该页；如果该位为 1，将该位设为 0，将其移到队尾，看成新装入的页。
   - 优点：一定程度上，避免把经常使用的页面置换出去  
     ![](/media/16013705538675.jpg){: width="400px"}
4. 时钟置换法（Clock）：对第二次机会置换法的改进。第二次机会置换法需要在链表中移动页面，而时钟置换法将页面保存在环形链表中，只需要后移队头指针，就相当于是把原来的队头放到队尾了。
   - 优点：避免了移动链表节点的开销  
     ![](/media/16013705785727.jpg){: width="400px"}
5. 最近最少使用法（LRU：Least Recently Used）：优先淘汰最久未被访问的页面。根据局部性原理，一个进程在一段时间内要访问的指令和数据都集中在一起。如果一个页面很久没有被访问，那么将来被访问的可能性也比较小。
   - 优点：实验证明 LRU 的性能较好，能够降低置换频率
   - 缺点：存在**缓存污染**问题，即由于偶发性或周期性的冷数据批量查询，热点数据被挤出去，导致缓存命中率下降
   - 适用场景：访问分布未知的情况；[redis] 要求热点数据有效；[redis] 应用对缓存的访问符合二八定律 / [幂律分布](http://wiki.swarma.net/index.php/%E5%B9%82%E5%BE%8B%E5%88%86%E5%B8%83)
6. LRU-K：LRU-K 算法的核心思想是将“最近使用过 1 次”的判断标准扩展为“最近使用过 K 次”，LRU 可以认为是 LRU-1。能够降低“缓存污染”的问题。
7. 最近最不经常使用法（LFU：Least Frequently Used）：优先淘汰最近访问频率最少的数据。
   - 优点：能够避免缓存污染问题对 LRU 的命中影响
   - 缺点：存在**访问模式问题**，即如果访问内容发生较大变化，LFU 需要用更长的时间来适应，导致缓存命中率下降；维护相关数据结构的开销大
   - 适用场景：[redis] 数据的访问模式固定
8. 随机淘汰法（Random）：实现简单，不需要保留有关访问历史记录的任何信息
   - 适用场景：[redis] 如果应用对于缓存 key 的访问概率相等，则可以使用这个算法

操作系统常用的是 LRU 算法；一般数据的访问模式是随时间变化的，所以大多数的缓存也都是使用 LRU 算法或其变种。还有一些其他算法如 MRU、SLRU 等，见[维基百科](https://en.wikipedia.org/wiki/Cache_replacement_policies)。

</details>

### 虚拟地址空间的组成部分

- 虚拟地址空间的组成部分
- 栈的作用、增长方向
- 堆的作用、增长方向
- 栈和堆的区别

<details markdown="1">
<summary>答案</summary>

**(1) 虚拟地址空间的组成部分**

整体上，操作系统将每个进程的虚拟地址空间划分成两个部分：内核空间和用户空间。内核空间存放的是内核代码和数据，用户空间存放的是用户程序的代码和数据。在 32 位操作系统中，一般将最高的 1G 字节作为内核空间，而将较低的 3G 字节作为用户空间。

进程运行在内核空间时，处于内核态，此时可以执行任何特权指令。每个进程的内核空间都是**相同**的，用户代码无法访问内核空间。

虚拟地址空间的完整组成：

![](/media/16014573476226.jpg)

从上往下依次是：

- 内核虚拟空间 {::comment}（不是内核栈，而是包含内核栈。它的划分和用户空间应该是一致的）{:/comment}
- 用户栈：从高地址向低地址增长
- 共享库：动态链接阶段
- 运行时堆：从低地址向高地址增长
- 程序代码和数据：从可执行文件中加载（代码段、数据段、BSS 段）

**(2) 栈**

用户栈其实就是函数调用栈，作用主要是：

- 保存函数的局部变量
- 保存某些寄存器的值
- 向被调用函数传递参数
- 返回函数的返回值
- 保存函数的返回地址

每个函数在执行过程中都需要使用一块栈内存用来保存上述这些值，这块栈内存为该函数的栈帧（stack frame）。栈的增长和收缩由编译器插入的代码**自动完成**，随着函数的调用而分配，随函数的返回而自动释放。程序员无需关心，这一点与堆不同。

**(3) 堆**

栈内存的分配需要实现确定其大小，而堆内存允许程序在运行时动态申请某个大小的内存空间。申请的内存在函数退出后依然保留，需要手动释放。C 语言中的 `malloc` / `free` 就是从堆中分配 / 释放内存，操作系统通过一个记录空闲内存地址的链表来管理堆内存。

如果反复向操作系统申请堆内存而不释放，会导致**内存泄漏**。在 C / C++ 中，必须由程序员手动释放堆内存。而 Java / Golang 中有垃圾回收器，会定期主动回收内存。但是即使有垃圾回收器，也有内存泄漏的风险，比如长期持有某个大对象的引用。

**(4) 栈和堆的区别**

1. 增长方向：栈向低地址方向增长，堆向高地址方向增长
2. 申请回收：栈自动分配和回收，堆需要手动申请和释放
3. 生命周期：栈的数据仅存在于函数运行过程中，堆的数据只要不释放就一直存在
4. 连续分配：栈是连续分配的，堆是不连续的，容易产生内存碎片
5. 空间大小：栈的大小是有限的（如默认 8M，Linux 上通过 `ulimit -s` 查看），而堆的空间较大，受限于系统中有效的虚拟内存

</details>

### 大端法、小端法

- 什么是大端法、小端法？
- 如何判断一台机器是大端法还是小端法？
- 面试真题：判断以下程序在 32 位机器上的输出

  ```c
  int main() {
    int a = 0x1234;
    char *p = (char *)&a;
    printf("%02x\n", *p);
    printf("%02x\n", *(p + 1));
    printf("%02x\n", *(p + 2));
    return 0;
  }
  ```

<details markdown="1">
<summary>答案</summary>

1. 计算机最小的可寻址的内存单位是字节。按有效字节在内存地址中从小到大的存储顺序，可以分为大端法和小端法：大端法从高位到低位存储，小端法从低位到高位存储。比如某个 int 型整数的值为 `0x01234567`，存储在 `0x100`~`0x103` 的内存地址上。大端法和小端法的字节顺序如下所示：  
   ![-w500](/media/15978352436370.jpg)
2. 按内存地址顺序从低到高输出一个变量的全部字节，可以借助 `char*` 类型的指针来完成，见[答案]({% post_url 2019-11-30-csapp-2%}#judge-big-end)
3. 小端法输出 `34 12 00`，大端法输出 `00 00 12`，见[答案]({% post_url 2019-11-30-csapp-2%}#big-end-question)

</details>

### 缓冲区溢出问题

- 什么是缓存区溢出？
- 缓冲区溢出攻击的方式
- 缓冲区溢出攻击的防范方法

<details markdown="1">
<summary>答案</summary>

C 语言使用运行时栈来存储过程信息。每个函数的信息存储在一个栈帧中，包括寄存器、局部变量、参数、返回地址等。C 对于数组引用不进行任何边界检查，因此**对越界的数组元素的写操作会破坏存储在栈中的状态信息**，这种现象称为缓冲区溢出。

![-w306](/media/16017022870641.jpg){: width="400px"}

缓冲区溢出会破坏程序运行，也可以被用来进行攻击计算机，如使用一个指向攻击代码的指针覆盖返回地址。

![](/media/16017013835258.jpg){: width="400px"}

防范缓冲区溢出攻击的机制有三种：随机化、栈保护和限制可执行代码区域。

**(1) 随机化**

使用缓冲区溢出进行攻击，需要知道攻击代码的地址。因此常见的防范方法有：

1. 栈随机化：程序开始时在栈上分配一段随机大小的空间
2. 地址空间布局随机化（Address-Space Layout Randomization，ASLR）：每次运行时程序的不同部分，包括代码段、数据段、栈、堆等都会被加载到内存空间的不同区域

但是攻击者依然可以使用蛮力克服随机化，这种方式称为“空操作雪橇（nop sled）”，即在实际的攻击代码前插入很长的一段 nop 指令序列，执行这条指令只会移动到下一条指令。因此只要攻击者能够猜中这段序列的某个地址，程序就会最终经过这段序列，到达攻击代码。

因此栈随机化和 ASLR 只能增加攻击一个系统的难度，但不能完全保证安全。

**(2) 栈保护**

在发生缓冲区溢出、造成任何有害结果之前，尝试检测到它。常见的栈破坏检测方法是栈保护机制：在每个函数的栈帧的局部变量和栈状态之间存储一个**随机产生的**特殊的值，称为金丝雀值（canary）。在恢复寄存器状态和函数返回之前，程序检测这个金丝雀值是否被改变了，如果是，那么程序异常终止。

![](/media/16017017141684.jpg){: width="400px"}

**(3) 限制可执行代码区域**

内存页的访问形式有三种：可读、可写、可执行。只有编译器产生的那部分代码所处的内存才是可执行的，其他页应当限制为只允许读和写。以前 x86 将读和执行视为一个标志位，可读就可执行，为了限制某些页可读但不可执行，往往会带来严重的性能损失。现在新的处理器在硬件上引入新的位，将读和执行分开，由硬件来检查页是否可执行，效率上没有损失。

</details>

### 进程的内存管理

- `malloc`、`free` 的原理
- `tcmalloc` 的原理
- Golang 的内存分配原理
- 线程、协程的栈空间实现

### I/O 模型

- 5 种 I/O 模型
- 同步 I/O 和异步 I/O
- 阻塞 I/O 和非阻塞 I/O
- I/O 多路复用：select / poll / epoll
  - 原理
  - 区别
  - 适用场景
  - 水平触发、边缘触发
  - 为什么边缘触发必须使用非阻塞 I/O？
  - 为什么 Redis 单线程模型依然效率很高？

<details markdown="1">
<summary>答案</summary>
- 5 种 I/O 模型：阻塞 I/O、非阻塞 I/O、信号驱动式 I/O、I/O 多路复用、异步 I/O（AIO）
- I/O 同步和异步的区别在于：将数据从内核复制到用户空间时，用户进程是否会阻塞（需要用户进程来完成）
- I/O 阻塞和非阻塞的区别在于：进程发起系统调用后，是会被挂起直到收到数据后在返回、还是立即返回成功或错误
![](/media/16010947228749.jpg)
- I/O 多路复用 [答案]({% post_url 2020-02-27-select-poll-epoll %})
</details>

### 协程

### 写时复制 Copy-on-write

- 为什么需要 COW？
- 实现原理
- 优缺点
- 实际应用

[答案]({% post_url 2020-09-06-copy-on-write %})

## 计算机网络

### 协议栈

- OSI 协议栈
- TCP/IP 协议栈
- 每一层的作用
- 每一层的常见协议与作用

[答案]({% post_url 2020-07-08-protocol-stack %})

### 两台主机间的通信过程

TODO：ARP、IP

### TCP 如何保证传输的可靠性

TODO：序列号、重传

### TCP 的流量控制和拥塞控制

- 发送端如何控制自己的发送速率
- 为什么快速重传不需要像超时重传那样，重新开始慢启动？
- 如何计算理论场景的最大吞吐量

TODO

### TCP 的三次握手和四次挥手

- 三次握手、四次挥手过程
- 握手阶段、传输阶段、挥手阶段的序列号与确认号
- 为什么客户端 TIME_WAIT 需要等待 2MSL
- 为什么需要三次握手，而不是两次或四次
- 为什么需要四次挥手，而不是三次
- SYN 攻击的原理

[答案]({% post_url 2020-07-08-tcp-shake-wave %})

### TCP、UDP 对比

- 二者区别
- 适用场景

### HTTP 原理

- HTTP 请求方法、GET 和 POST 的区别？
- HTTP 状态码
- 301/302 重定向原理
- 304 缓存原理，不同缓存头的区别
- HTTP/1.1、2.0 引入的变化
- HTTP/2.0 关键特性：压缩首部、服务端推送、多路复用
- HTTP 请求报文、响应报文的格式
- Cookie 和 Session 的区别

[答案]({% post_url 2020-08-22-http%})

### HTTPS 原理

- HTTPS 四次握手过程
- 访问的网站是如何自动切换到 HTTPS 的
- 什么是中间人攻击？如何预防？

### DNS 的解析过程

递归查询、迭代查询

### IP 原理

- IP 号分类规则
- 如何划分子网
- IP 分组转发规则
- 什么是 NAT 协议
- 什么是 ARP 协议
- 集线器、网桥、交换机、路由器位于哪一层
- 为什么局域网的 IP 普遍是 192.168 开头

### 从输入一个 URL 到页面加载完成的过程

[答案]({% post_url 2020-02-26-what-happens-when-you-type-in-a-url %})

## 数据库

### 数据库的存储引擎

- MySQL 支持哪些存储引擎
- 不同存储引擎的区别、适用场景
- InnoDB 引擎的原理
- 如何选择存储引擎

[答案]({% post_url 2020-08-06-db-engine%})

### 数据库的索引

- 索引类型
- 索引的实现原理
- 如何设置索引

### 数据库的事务

- 事务的特性
- 事务可能存在的并发问题
- 事务的隔离级别，各个隔离级别可能发送的问题

### 数据库的并发控制

乐观锁、悲观锁、MVCC

### 数据库分库、分表、主从、读写分离

- 数据库主从复制的原理（binary log），为什么使用？

### 数据库的优化方法

### 数据库内连接、外连接的含义

### ORM 和原生 SQL 的区别

### Redis 相关

- 为什么使用 Redis
- Redis 基本数据类型和使用场景
- Redis 持久化方案对比
- Redis 线程模型
- 缓存雪崩 / 缓存穿透 / 缓存击穿及其解决方案

## 数据结构

### 哈希表

- 哈希表的实现方式
- 哈希表冲突解决方法
- 哈希表如何查找数据

### Map 的实现

- Java HashMap 实现原理
- Go map 原理
- map 使用不同数据结构实现的区别

## 计算机组成原理

- 引用和指针的区别
- 函数的参数是如何传递的
- 大端法、小端法及其判断 [答案]({% post_url 2019-11-30-csapp-2%}#big-end)

## 多线程编程

- 两个线程交替打印奇偶数 [Bilibili 视频课](https://www.bilibili.com/video/BV1Lv411v71U)

## 开发与运维

### Linux 常用命令

- 如何搜索某个目录下带有指定字符的的文件
- 如何查看某个端口的进程
- ......

## 分布式

- 消息队列的作用，原理
- 分布式概念（服务注册、服务监控、负载均衡等）
- 分布式系统一致性、CAP、BASE 理论
- 分布式共识算法：Paxos，Raft
- 分布式事务的相关算法：两阶段提交、三阶段提交
- etcd
- memcache：内存管理（内存结构、分配方式、回收方式）、分布式（实现原理、分布式算法）
- ZooKeeper：工作过程、zab 协议、节点类型、Watcher、会话

## 网络安全

- XSS：原理、攻击、防御
- CSRF：原理、防御
- 浏览器的同源策略、CORS

## 面经汇总

- [wolverinn/Waking-Up](https://github.com/wolverinn/Waking-Up?utm_source=gold_browser_extension)：计算机基础面试题汇总，速问速答
- [计算机网络太难？了解这一篇就够了](https://juejin.im/post/5d896cccf265da03bd055c87)：计算机网络题目汇总
