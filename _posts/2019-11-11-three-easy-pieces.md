---
layout: post
cover: false
navigation: false
title: Gettysburg Address
date: 1863-11-19 10:18:00
tags: fiction
subclass: 'post tag-fiction'
author: abraham
categories: abraham
---

# 第一部分：虚拟化

## 基础

**系统调用**：“系统调用”并不是将操作系统的行为提供成一个标准库，通过“程序调用”的方法去访问它。而是通过一对特殊的硬件指令和硬件状态来使得转移进 OS 变得更正式、可控。
系统调用：硬件特权等级。用户程序在用户态运行。OS 程序在内核态运行。系统调用通过一个硬件指令：trap 来初始化，然后将控制权转给 trap handler，然后特权等级提升为内核态。

## 进程与线程

### 概念

**上下文切换**：上下文就是寄存器中的值。

## 5. 进程 API

这三个都是系统调用

### fork

子进程从调用 fork 的地方开始执行，因此第一行代码不会在子程序里执行。子进程和父进程几乎一模一样，但是 fork 的返回值不同。

> [进程间通信的方式——信号、管道、消息队列、共享内存](https://www.cnblogs.com/LUO77/p/5816326.html)
> 该函数被调用一次，但返回两次。两次返回的区别是子进程的返回值是 0，而父进程的返回值则是新进程（子进程）的进程 id。将子进程 id 返回给父进程的理由是：因为一个进程的子进程可以多于一个，没有一个函数使一个进程可以获得其所有子进程的进程 id。对子进程来说，之所以 fork 返回 0 给它，是因为它随时可以**调用 getpid()来获取自己的 pid；也可以调用 getppid()来获取父进程的 id**。

### wait

父进程等待子进程调用结束。

### exec

运行不同的程序。调用该系统调用的时候，会加载可执行文件并覆盖当前代码段，堆栈以及其他内存空间被重新初始化，因此原来的代码将不会再执行。这相当于它并没有创建一个新的进程，而是将另一个进程转移到当前进程内。

#### 同样都是创建一个新的进程，为什么要区分 fork 和 exec？

这两个 API 对于 shell 很重要。它使得 shell 能够在 fork 之后、exec 之前执行一些代码，比如替换即将要运行的代码的环境。比如重定向符 `>` 的实现。要先使用 fork()，然后进行 IO 重定向到文件，然后再执行 exec。

> 我觉得这是 UNIX 的设计哲学：提供“完整且最小”的接口，即一组正交的接口。
> [为什么 Linux 下要把创建进程分为 fork()和 exec()(一系列函数)两个函数来处理? - pansz 的回答 - 知乎](https://www.zhihu.com/question/66902460/answer/247267780)

## 6. 受限直接执行（LDE）

虚拟化 CPU（时分技术）的问题：

1. 高性能
2. 控制（限制访问资源等）

直接执行就是直接将代码加载到 CPU 上执行，优点是很快，但是其问题是：

1. 如何限制代码不执行那些不期望的行为
2. 在运行这个程序的时候如何切换到另一个程序

因此，操作系统必须“限制直接执行”（Limited Direct Execution）。

### 执行受限代码：用户态和核心态

#### 陷入内核

那么限制执行的时候程序要如何一些受限操作？解决办法是引入处理器模式：用户态和核心态。用户态无法执行受限操作，如 I/O 请求，执行这些操作会引发异常。核心态由操作系统运行，可以执行特权操作。那么用户程序如何调用这些特权操作呢？答案是通过系统调用 system call。

要执行系统调用，必须通过一个特殊的**陷入（trap）**指令来进入内核态。执行完成后，操作系统会调用**从陷入返回（return-from-trap）**指令返回到调用指令，同时退回到用户态。每个程序都有一个内核栈（kernel stack），陷入到内核之前，操作系统需要将寄存器、计数器等保存到内核栈中，在返回时弹出以 xian'ru 恢复程序。

陷入指令如何知道要执行操作系统的哪条指令？肯定不能由调用程序来指定跳转的位置。答案是通过 trap table。机器启动的时候会处于内核态，因此可以设置 trap table。OS 会在这个表格中设置代码位置（trap handlers），从而在用户输入（按下键盘）、发生中断、发生系统调用等时候知道要执行哪里的代码。

设置 trap table 本身也是一个内核态才能执行的特权操作。

#### 中断（interrupt）与陷入内核（trap）

用户态无法执行特权操作如 I/O，需要发出系统调用以陷入（trap）内核，在核心态执行特权操作。陷入内核时，OS 会在 trap table 中找对应的 trap handler，执行相应的 system routine。

中断(interrupt)指特定时机 CPU 暂时停止当前程序的执行、转而执行处理新情况的程序和执行过程。OS 使用中断向量(interrupt vector)保存各种设备的中断处理子程序的地址。

interrupt 即外中断，指来自处理机和内存外部的中断，包括 I/O 设备发出的 I/O 中断、外部信号中断、各种定时器引起的时钟中断以及调试程序中设置的断点等引起的调试中断等，是硬件产生的中断。

trap 即内中断，指在处理机和内存内部产生的中断。包括程序运算引起的各种错误、系统调用等。在内核态执行完成后，OS 会调用 return-from-trap 指令返回到调用指令，同时退回到用户态。

发生中断和陷入的时候都会将控制权交给 OS，OS 可以选择执行某个进程（调度 Schedule）。

#### 以 open() 系统调用为例

trap 的角度：在调用 open 或 read 的时候，标准库会按照某种约定设置栈或者寄存器的值，以向内核传递参数，然后再执行系统调用。当从内核态返回时，标准库会解析返回值，然后将控制权移交给调用的程序。

中断/并发的角度：open 会阻塞，因为 CPU 的速度远远大于从硬件读取内容的速度。如果一直等待，会造成 CPU 的浪费。因此当某个进程调用 open 时，OS 会挂起这个进程，CPU 在这个时间段可以执行别的任务。读取任务实际上由 DMA 完成，当读取完毕后，DMA 会发出一个 I/O 中断通知 OS，从而执行相应的中断处理程序，切换回被挂起的进程操作文件。

> [I/O 会一直占用 CPU 吗](https://www.zhihu.com/question/27734728) > [第十二章：外设管理](mweblib://15584340653507)

#### 受限直接执行协议（LDE Protocol）

分为两个阶段：启动时，运行进程时。
![-w697](media/15696405470407/15707970483119.jpg)

### 在进程间切换

当一个程序在执行的时候，相当于 OS 没有执行。那么问题变为如何将控制权恢复给 OS？（regain control）

一种协作（cooperative）的途径是：当程序在运行的时候，主动执行一个特别的系统调用**yiyeld**，**放弃** CPU。当程序出错如除以 0 或者下标越界的时候，会陷入内核，这时 OS 也会获得控制权。但是如果程序陷入死循环，将永远无法切换进程。

另一种非协作的方式让 OS 来获得控制。在没有协作的情况下，OS 获得控制权的方式是时钟中断（timer interrupt）。每各若干毫秒，时钟中断会发生，当前运行的进程被暂停，转而由 OS 运行中端处理器（trap table 预先配置）。这时 OS 便获得了 CPU 的控制权。

要在 boot 启动的时候启动 timer。启动 timer 本身也是一个特权指令。timer 可以被关闭。

当发生时钟中断的时候，硬件需要保存当前运行的程序的上下文信息以便之后从陷入返回的时候继续执行。这个行为和程序主动执行系统调用几乎一样——将上下文保存在该进程的内核栈中。

#### 保存与恢复上下文

在切换进程前将**寄存器的值、程序计数器以及当前进程的内核栈指针**保存在当前运行的进程的内核栈中，下次运行该进程前，从内核栈弹出并恢复。通过这种机制使得 OS 在 return-from-trap 指令发生的时候，不需要执行上次运行的进程，而是可以切换到任何进程去。这样叫做“调度” schedule。

将上下文信息保存在当前进程的内核栈后，操作系统会切换内核栈到即将要执行的进程、恢复上下文、然后执行 return-from-trap 指令，进入将要执行的进程（而不是发生时钟中断、陷入内核的那个进程），完成上下文切换。其时序图如下：
![-w746](media/15696405470407/15707989318431.jpg)

#### 调度的时机

只要控制器移交给 OS，就可以进行一次调度：

- 用户空间：可以通过 yield 主动放弃 CPU
- 时钟中断、I/O 中断等，控制器交给 OS
- 用户进程发出系统调用：会陷入内核

### 并发执行的问题

比如在处理一个内核陷入时，时钟中断发生了，该怎么办？简单的说，当 OS 正在处理中断时，它会**关中断**；同时 OS 有**锁机制**来处理并发执行的同步问题。

## 13. 地址空间

地址空间包含的内容：

1. 代码 code
2. 栈 stack：局部变量、函数调用等
3. 堆 heap：动态分配的内存如 new

![-w553](media/15696405470407/15708793428742.jpg)
代码是固定大小，因此可以从 0 开始放置。图中堆和栈放在两端，因为二者都会动态增长。但是这只是内存分配的一种方式，还有其他方式，比如多线程时的内存分配。

要注意上图只是地址空间的抽象，实际上在物理内存中这些存储内容并不是连续的。

打印出代码、堆和栈的地址后可以看到，代码在地址空间的最前面，下来是堆，而栈在最末端：

```c
#include <stdio.h>
#include <stdlib.h>
int main(int argc, char * argv[]) {
    printf("location of code : %p\n", (void * ) main);
    printf("location of heap : %p\n", (void * ) malloc(1)
    );
    int x = 3;
    printf("location of stack : %p\n", (void * ) &x);
    return x;
}
/*
location of code : 0x1095afe50
location of heap : 0x1096008c0
location of stack : 0x7fff691aea64
*/
```

不过要注意，代码里打印出来的地址也是虚拟地址。

## 14. 内存 API

### 内存的类型

栈：由编译器隐式完成内存分配和回收。比如局部变量
堆：由开发者决定分配和回收时机

### malloc() 调用

接收一个整数作为申请堆上内存的大小，常见的使用方式：

```c
malloc(sizeof(double))
```

`sizeof` 上会在编译的时候被替换。

### free()

参数是 malloc 返回的指针。有些语言不需要主动调用 free，而是会通过垃圾回收机制来释放内存。

忘记释放内存会导致内存泄露，可能导致内存被用尽。杀死该程序，操作系统会回收分配给它的页面。
即使有垃圾回收机制，如果保留某个内存块的引用的话，这块内存也可能无法回收。

### mmap()

同样可以申请内存，内存位于“交换空间 swap space”，不与任何文件关联。

### 总结

malloc、free 并不是系统调用，而是库函数。它们内部会进行系统调用，要求 OS 分配内存。其底层调用了是 brk 和 sbrk 系统调用，会通过改变程序的 break（堆的末端的位置）来调整堆大小。

## 15. 内存

### 地址重定向

动态重定向：基于硬件的重定向，与静态重定向相对。
静态重定向：通过 loader 程序重写指令中的地址。

将虚拟地址（经过硬件)转化为真实地址的技术称为地址转译。因为 base 地址是在运行时确定，即使程序运行后也能更改其真实地址，所以这个技术也叫动态重定向。

base 寄存器用来转换地址，bound 寄存器保证地址在地址空间里，不合法的访问会导致一个异常。这两个结合要一起就是 CPU 里的 MMU（内存管理单元）。

## 18. 19. 分页

[第七章：内存管理](mweblib://15584305536222)
[第八章：虚拟内存管理](mweblib://15584312810934)

进程的地址空间分为页面（page），物理内存分为页框（page frame）。

### TLB

转换检测缓冲区（TLB，translation-lookaside buffer），是 MMU（内存管理单元）的一部分。

空间局部性：如果程序访问了 x，那么很有可能访问 x 附近的地址
时间局部性：如果程序访问了 x，很可能立刻又访问 x

连续遍历数组时，命中率很高，因为 TLB 每次缓存的是一整个页面的地址。如果页面够大的话，访问 array 时的 TLB miss 概率更低了。这是 TLB 通过“空间局部性”改进性能。

> 因此，遍历一个二维数组时，按行遍历比按列遍历的效率更高（Cacheline，见[操作系统的缓存机制](mweblib://15708673498503)）

如果很快访问一个旧的数组，这时候更不会 miss 了，因为之前的缓存还没有失效。这是对“时间局部性”的利用。

### 如何处理 TLB miss？

硬件处理：复杂指令集的 CPU 如 x86 会使用硬件处理。硬件使用一个寄存器来保存页表基址。x86 使用的是多级页表。

软件处理：精简指令集使用的方法，即 TLB miss 的时候抛出异常、陷入内核，由操作系统更新 TLB。

### 上下文切换

TLB valid 位在上下文切换的时候起作用，保护进程不使用过时的转译信息。上下文切换的时候处理 TLB 的两种方法：

1. 清空，开销大
2. 硬件增加一个 ASID 位记录某个表项对应于哪个进程，操作系统要标识当前进程

### 置换算法

TLB 的置换算法也是 LRU。

# 第二部分：并发

## 26. 27. 并发：简介

### ---

多进程是不会有并发问题的，因为每个进程的虚拟地址空间都是独立的。但是多线程会有并发问题，因为它们会共享一个进程的地址空间。

线程的上下文切换过程：线程有自己的寄存器。当上下文切换的时候，正在运行的线程会将寄存器的状态保存到 TCB 里（进程是 PCB），然后恢复另一个线程的上下文。但是和进程的区别是：线程切换不会改变地址空间，也就是说不需要重新加载页表。

多线程共同修改某一个全局变量，可能出现结果不正确的问题。比如每个线程将该变量增加 100，两个线程并发的时候，变量最后可能是 170 而不是 200。这是因为**线程调度的时间是不确定的，而赋值操作也不是原子的**。以下是一个增加 1 的操作的汇编指令：

```
mov 0x8049a1c, %eax
add $0x1, %eax
mov %eax, 0x8049a1c
```

假设线程 A 先运行。从地址`0x8049a1c`读取变量，存入寄存器；寄存器中的值加 1；寄存器中的变量保存回内存。问题就发生在第 2、3 条指令：如果在运行第二条指令后发生了线程调度，那么当前线程 A 的寄存器信息会保存到 TCB 中，转而执行另一个线程 B。由于每个线程都有自己独立的寄存器，因此线程 B 并不知道线程 A 修改了这个变量（没有保存回磁盘），所以它访问到的全局变量的值依然是旧的值。当再次切换回线程 A 时，开始执行剩下的指令：`mov %eax, 0x8049a1c`，相当于线程 B 白执行了。
![-w782](media/15696405470407/15723432173695.jpg)

这种不确定的情况称为“**竞态条件**”：多个线程都尝试更新一个共享的数据结构，导致执行结果取决于代码执行的时机，即“不确定的”。

导致“竞态条件”发生的代码称为“**临界区**”，临界区就是访问共享资源的代码片段。我们希望这部分代码在多线程中能**互斥**执行，以保证每次**只有一个线程在临界区中**运行。

> 互斥：共享资源，不能同时执行
> 同步：共享资源，需要等待另一个线程完成后再继续

解决这个问题的一个办法是由硬件提供**原子性**的指令：一条指令完成“内存加 1”的操作，这样就不会有中间状态。原子性表示“要么做，要么不做 / all or none”。但是原子性指令不够通用，因此可以构建一个通用的**同步原语**（synchronization primitives）的集合。

于是问题就变成了：硬件要如何提供这类同步原语的支持？操作系统又该提供哪些帮助？

### 线程 API

#### 创建线程

与线程相关的 API 有以下几个：

- `Pthread_create`：创建线程
- `Pthread_join`：等待一个线程结束，并获取线程的返回值

要注意，线程的返回值不能是一个指向在线程的栈内分配的变量的指针，因为线程返回的时候，分配给它的栈会被回收。

#### 锁

```c
int pthread_mutex_lock(pthread_mutex_t * mutex);
int pthread_mutex_unlock(pthread_mutex_t * mutex);
```

加锁和解锁的时候需要检查返回值，判断这些例程调用是否成功。

锁必须初始化后才能使用，使用完后需要销毁：

```c
pthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER; // 或者
int rc = pthread_mutex_init(&lock, NULL);
assert(rc == 0); // always check success!

pthread mutex destroy();
```

#### 条件变量（Condition Variables）

条件变量用于一个线程等待另一个线程返回后再继续执行的情况。

```c
int pthread_cond_wait(pthread_cond_t * cond, pthread_mutex_t * mutex);
int pthread_cond_signal(pthread_cond_t * cond);
```

第一个例程会传进一个条件变量与一个锁，让当前线程休眠，直到另一个线程发送了信号。

要注意，在使用条件变量的时候，如果修改了共享变量，还是要先加锁。比如下面这段代码：

```c
pthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER;
pthread_cond_t cond = PTHREAD_COND_INITIALIZER;

Pthread_mutex_lock(&lock);
while (ready == 0)
    Pthread_cond_wait(&cond, &lock);
Pthread_mutex_unlock(&lock);
```

上面代码有个问题：当线程在循环内部调用`Pthread_cond_wait`休眠的时候，它就不会执行`Pthread_mutex_unlock`解锁了，那另一个线程怎么再获取这个锁？

答案是在`Pthread_cond_wait`的第二个参数。`Pthread_cond_wait`会先释放第二个参数的这个锁，再将当前线程休眠。而在当前线程被唤醒之前，`Pthread_cond_wait`会重新获取这个锁。

不要不使用条件变量而是使用一个标志位，比如上面的代码可以写成这样：

```c
while (ready == 0) ;
// --- 另一个程序
ready = 1;
```

一是会浪费 CPU，二是可能有错误。要永远使用条件变量来在线程间传递信号。

## 28. 锁

一个锁就是一个变量，类型是 mutex。当一个线程调用 `lock()` 获取锁时，如果另一个线程正持有该锁，那么 `lock()` 将不会返回，直到持有锁的线程通过 `unlock()` 释放锁。在任何时候锁只能被一个线程持有，因此只有一个线程能进入临界区。

使用细粒度而不是粗粒度的锁策略，这样能有多个线程位于不同的临界区，可以提升并发性。

### 禁止中断

如何实现一个锁？对于硬件和操作系统有什么要求？简单的方法是当进入临界区的时候禁止中断，这种方法只适用于单 CPU 的场景。优点是实现简单，缺点却很多：给用户禁止中断的权利很危险，可能永远不开中断；在多 CPU 的情况下，其他 CPU 还是可以访问临界区（不同的 CPU 有自己的时钟中断器）；关中断可能造成某些中断信号丢失，比如磁盘存取完成了；最后就是这种办法效率很低。因此“禁止中断”这种方法只适用于 OS 自己在访问某些数据结构、要保证原子性的时候。

### Test-And-Set

另一种办法是 Test And Set。即设置一个忙标志位。当一个线程想要进入临界区时，检测忙标志，如果为 0，等待，如果为 1，将其设为 0，然后进入临界区。一种简单的实现是硬件不提供这样的原子指令，而是单纯的软件层实现：
![-w473](media/15696405470407/15726668157910.jpg)
这种方法的缺点是：锁有可能不正确，导致两个线程都进入临界区。这可以通过硬件帮助来实现，关键在于要保证“检测”与“设置”的原子性。在不同的处理机上，都有类似的专用机器指令，统称为 test and set instruction。它们执行的操作类似于下面的 C 代码：获取某个变量的旧值（test），并同时将该变量更新为新值（set），这两个动作是原子的：

```c
int TestAndSet(int * old_ptr, int new) {
    int old = *old_ptr; // fetch old value at old_ptr
    *old_ptr = new; // store ’new’ into old_ptr
    return old; // return the old value
}
```

可以这样执行一个加锁操作：

```c
void lock(lock_t * lock) {
    while (TestAndSet(&lock->flag, 1) == 1)
        ; // spin-wait (do nothing)
}

void unlock(lock_t * lock) {
    lock->flag = 0;
}
```

`TestAndSet` 会返回旧的值，所以当 lock 为 1 的时候，说明正在被其他线程持有，将继续循环。直到其他线程释放锁，这时锁的值为 0。当前线程调用`TestAndSet`将锁设置为 1，返回旧值 0，加锁成功，进入临界区。

Test And Set 又称自旋锁（spin lock），是一种忙等待的锁。它是最简单的锁实现，就是空转 CPU。在单处理器的情况下，需要配合抢占式调度器(preemptive scheduler)而不是时分调度器(time slicing)。抢占式调度器是指一旦高优先级别的任务准备就绪之后，它就会马上被调度而不等待低优先级的任务主动放弃 CPU。而通用 OS 的时间片轮转调度算法是只有当任务主动放弃 CPU 后高优先级的任务才有调度的优先权。采用抢占式调度器能够避免当前线程白白空转 CPU（因为如果其他线程正持有锁的话，当前线程在运行的过程中是永远不可能获取到这个锁的）。

最后评价一下自旋锁的效率。毫无疑问它是*正确*的，即每次只能有一个线程进入临界区。但它不是*公平*的，可能导致饥饿。在单处理器上它的*性能*较差，某个线程无法尝试获取一个已经加锁的锁时，可能整个时间片都在空转；但是在多处理器上性能较好（线程均匀地分布在多个处理器上），空转周期可能变短——当处理器 A 上的线程 A 解锁时，处理器 B 上的线程 B 如果还有时间片剩余，便可以取得锁，进入临界区执行后续代码。

### Compare-And-Swap

Compare-And-Swap 是另一个有硬件提供的指令，基本思路是检测某个地址保存的值是否等于*期望值*，如果是，更新该地址为某个*新值*，否则什么都不做，最后都会返回该地址原来的值。代码如下表示：

```c
int CompareAndSwap(int *ptr, int expected, int new) {
    int actual = * ptr;
    if (actual == expected)
        *ptr = new;
    return actual;
}
```

用来加锁的操作可以改为如下所示：

```c
void lock(lock_t *lock) {
    while (CompareAndSwap(&lock->flag, 0, 1) == 1)
        ; // spin
}
```

可以看到它和 Test And Set 唯一的区别就是 Test And Set 会直接将目标地址的值设为新值，而 Compare-And-Swap 会在目标地址的值等于期望值的情况下才将其设为新值。Compare-And-Swap 和 Test And Set 的行为是完全一致的。

### Load-Linked and Store-Conditional

这是两个指令，伪码如下：
![-w652](media/15696405470407/15727778134625.jpg)
Load-Linked 就是一个取指令，返回某个地址的值。关键区别在于 Store-Conditional，即只有当该地址没有被更新的时候才会保存值并返回成功。那么如何使用这两个指令构建一个锁？可以先自己想一下。
![-w594](media/15696405470407/15727780220677.jpg)
while 循环会一直检测直到锁被设为 0，表示锁已不被持有。这时会通过 StoreConditional 将锁设为 1，如果成功，表示**从上次检测锁变量后的这段时间里没有其他线程更新过锁**，因此便可进入临界区；否则失败，表示锁在*这段时间*被其他线程修改过（发生了竞态条件），需要重新检测锁变量。

最后是一个更简单的版本：

```c
void lock(lock_t * lock) {
    while (LoadLinked(&lock->flag)||!StoreConditional(&lock->flag, 1))
        ; // spin
}
```

### Fetch-And-Add

这个原语指令的作用是将某个地址的值加一，然后返回该地址的旧值。C 语言表示如下：

```c
int FetchAndAdd(int *ptr) {
    int old = *ptr;
    *ptr = old + 1;
    return old;
}
```

如何用这个指令实现一个锁呢？实现方法是交替地增加 ticket 和 turn：

```c
typedef struct __lock_t {
    int ticket;
    int turn;
} lock_t;

void lock_init(lock_t *lock) {
    lock->ticket = 0;
    lock->turn = 0;
}

void lock(lock_t * lock) {
    int myturn = FetchAndAdd(&lock->ticket);
    while (lock->turn != myturn)
        ; // spin
}

void unlock(lock_t * lock) {
    lock->turn = lock->turn + 1;
}
```

这条指令的原子性保证了加锁的时候不会有多个线程将 ticket 更新为同一个值。解锁的话就是简单地加 1 了。这个方法和之前的方法的重要区别是**它能保证所有线程的调度，不会出现饥饿的情况**。一旦某个线程取得了它自己的 ticket，它就一定会在将来某个时刻取得锁并进入临界区。其他的方法则没有这种保证，某个线程可能永远抢不到锁。

### Spin 存在的问题与 yield 系统调用

上面的四个原子性指令实现的锁都是采用 spin-waiting 的方式，这会有一个问题：如果锁已经被另一个线程持有，那么当前线程在尝试加锁的时候，实际上就是在空转 CPU。因为只有发生上下文切换、另一个线程释放锁，这个线程才能在它的下一个时间片获取到锁。这会造成性能浪费，尤其是线程数变多的时候，相当于每 N 个线程请求锁的时候，都会有 N-1 个线程的时间片在空转。

有没有什么优雅的方式能避免浪费 CPU 呢？单纯依赖硬件是无法实现的，我们需要操作系统的帮助。

一种简单的方法是：当一个线程要进入空转的时候，它主动让出 CPU 给其他线程。这需要操作系统提供一个系统调用 `yield`。一个线程有三种状态：Running、Ready、Blocked，`yield` 相当于把正在运行的线程从 **Running** 状态切换到 **Ready** 状态，相当于一次 deschedule。

这种方法解决了空转的问题，不过这里增加了上下文切换的频率，因此操作开销是比自旋大的。想象这样一个场景：我们有一个轮询的调度器与 100 个线程，当线程 1 持有锁并且在还没来得及释放锁的时候被中断了，那么调度器会依次调度其他 99 个线程。不出所料，这些线程都会调用 yield 让出 CPU，直到线程 1 再次被调度并释放锁。这里不仅上下文切换很频繁，而且也没有解决线程的饥饿问题。我们需要更好的方法。

### 使用队列：Sleeping 而不是 Spinning

造成饥饿的问题是线程的执行顺序是不定的。我们需要操作系统的帮助：使用队列记录线程的执行顺序。当一个线程访问其他线程持有的锁时，将其加入队列调用 `park()` 休眠；当锁被释放时，调用 `unpark(threadID)` 唤醒队列中的一个线程。

具体实现见下面的代码。guard 是*操作队列的锁*，而 flag 是*真正的锁*。这两个锁 1 都表示锁被持有，0 都表示锁被释放。
![-w541](media/15696405470407/15728625776681.jpg)
这种方法还是没有完全避免 spin-waiting，但是花费在 spinning 上的时间已经非常有限了：当一个线程无法获取到锁时，它会将自己加入队列，然后*休眠(Sleep)*而不是*空转(Spin)*，再次调度的时候也不会调度这个休眠态的线程。

上面代码的一个奇怪的点是：当 `unlock()` 中唤醒一个线程的时候，只执行了 `unpark()`，却没有将 `flag` 设为 0 表示锁被释放，这正常吗？答案是这不仅正常，而且非常必要。因为当一个线程被唤醒的时候，它是从 `park()` 中返回的，它已经没有能力再回到 `lock()` 的开头将 flag 设为 1。这个从队列中唤醒一个线程的过程可以理解为**将锁从释放锁的线程直接转移到了被唤醒的那个线程**。

上述代码还有可能发生竞态问题：如果线程 A 在将要运行 `park()` 之前被调度，恰好下一个运行的线程 B 释放了锁，那么线程 B 在释放锁时发出的 `unpark()` 信号就相当于**丢失**了，而 A 在再次被调度的时候将执行 `park()`，并永远的休眠下去。这种情况称为 wakeup/waiting race。解决办法是增加第三个系统调用：`setpark()`，表示某个线程*将要* park 但是还没有真的 park。如果在 `park()` 前切换到另一个线程，那么当另一个线程调用 `unpark()` 后，这个线程再执行 park 时会立即返回而不是进入休眠。修改后的代码如下：

```c
// 第 20 行
queue_add(m->q, gettid());
setpark(); // new code
m->guard = 0;
park();
```

> 先调用 setpark，再释放锁，操作系统就在调用 unpark 的时候，就可以判断是不是有不成对的 setpark，如果有，说明对应线程的 park 方法应该立刻返回。因此不会丢失 unpark 信号。
> 以前的版本在调用 unpark 的时候，并不能知道之后会有哪些线程调用 park，所以也就白白丢失了。除非使用一个变量记录丢失的 unpark 数量，然后在 park 里判断，不过这和上面的思路其实就差不多了。

### Two-Phase Locks：两阶段锁

第一阶段先空转一会儿，看看能不能获取到锁。如果不能，就进入第二阶段，也就是 sleep，只有锁被释放时才能被唤醒。两阶段锁是一种混合机制。

### Linux 的实现

futex，对应 Solaris 的 park() 和 unpark()。不同的操作系统实现细节有所不同，但是原理大致相似。

### Go 语言的实现

```go
// Mutex - 初版（2008）
export type Mutex struct {
    key int32;
    sema int32;
}

func (m *Mutex) Lock() {
    // xadd 应该相当于  Fetch-And-Add 指令
    if xadd(&m.key, 1) == 1 {
        return;
    }
    sys.semacquire(&m.sema);
}

func (m *Mutex) Unlock() {
    if xadd(&m.key, -1) == 0 {
        return;
    }
    sys.semrelease(&m.sema);
}

// 当前实现：使用 Compare-And-Swap
func (m *Mutex) Lock() {
	// Fast path: grab unlocked mutex.
	if atomic.CompareAndSwapInt32(&m.state, 0, mutexLocked) {
		if race.Enabled {
			race.Acquire(unsafe.Pointer(m))
		}
		return
	}
	// Slow path (outlined so that the fast path can be inlined)
	m.lockSlow()
}
```

## 30. 条件变量

### Condition Variable

有时候只是希望在达到某个条件时再唤醒线程。如果使用互斥锁写，需要不停的检查条件是否满足，造成空转和 CPU 浪费。如何让一个线程等待某个条件？可以使用条件变量（condition variable）。

条件变量实际上是一个队列。当状态不满足条件的时候，线程可以将自己推入队列去等待（waiting）；当其他线程改变状态的时候，可以唤醒一个或多个在这个条件上等待的线程以让它们继续运行（通过在条件 condition 上 signaling）。“条件变量”和 Dijkstra 的“私有信号量”的理念很相似。

C 语言中相关系统调用如下所示：

```c
pthread_cond_t c = PTHREAD_COND_INITIALIZER; // 声明一个条件变量，条件变量也需要初始化
pthread_cond_wait(pthread_cond_t *c, pthread_mutex_t *m); // wait()
pthread_cond_signal(pthread_cond_t *c); // signal()
```

可以看到 `pthread_cond_wait` 接受一个锁作为第二个参数。`pthread_cond_wait` 会假设当它被调用的时候，这个锁是加锁的状态。然后它会先释放这个锁，再将当前线程休眠（原子性的）。而在当前线程被唤醒之前，`pthread_cond_wait`会重新获取这个锁，再运行此线程。

### 生产者消费者问题

条件变量可以解决生产者/消费者问题。

### Covering Conditions

比如对于内存分配的场景，如果线程申请空间时内存不足，就会休眠，其他线程释放空间时再唤醒线程。但是不同的休眠线程等待的 size 不同，如何知道要唤醒哪个线程？最简单的方式是唤醒所有线程，每个线程都重新检查条件。这种条件称为 covering condition，唤醒操作不再是 `pthread_cond_signal()` 而是 `pthread_cond_broadcast()`。

## 总结锁的分类：自旋锁、互斥锁、条件锁、读写锁

如果自旋锁（spin lock）已经被别的执行单元保持，调用者就一直循环在那里看是否该自旋锁的保持者已经释放了锁，"自旋"一词就是因此而得名。上面的使用 Spinning 方式的都是自旋锁。

互斥锁（mutex）就是当获取锁失败时，将线程休眠，等到锁的状态改变时再唤醒。需要操作系统帮助管理锁。由于涉及到上下文切换，操作开销是比自旋锁大的，但是解决了 CPU 浪费的问题。

有时候只是希望在达到某个条件时再唤醒线程。如果使用互斥锁写，需要不停的检查条件是否满足，造成空转和 CPU 浪费。条件锁解决的并不是“互斥”的问题，而是“等待通知”的问题。

读写锁只允许一个 writer 持有，或者多个 reader 持有。适用于大并发 read 的场景。

## 31. Semaphore 信号量

### 简介

“信号量”是迪杰特斯拉提出的同步原语，能够解决所有同步问题。信号量既可以用作锁，也可以用作条件变量。信号量是一个有整型值的对象，有两个操作：`sem_wait()` 和 `sem_post()`（POSIX 标准），或者叫 `P()` 和 `V()`（迪杰特斯拉），或者叫 `down()` 和 `up()`。

> P、V 来自荷兰语 prolaag 和 verhoog，表示 decrease 和 increase

`sem_wait()` 会将信号量的值减一，如果信号量的值 ≥ 1 就立即返回，否则信号量的值为负，休眠调用者；`sem_post()` 会将信号量的值加一，如果此时有一个或多个线程正在休眠，则唤醒一个。可以看出来，信号量为负数的时候就表示有多少个线程正在休眠。

### 信号量实现锁

二元信号量：

```c
sem_t m;
sem_init(&m, 0, 1); // initialize semaphore to 1
sem_wait(&m);
// critical section here
sem_post(&m);
```

### 信号量实现条件变量

信号量应该设置为 0。等待条件的线程 A 调用 `sem_wait()`，满足条件的线程调用 `sem_post()` 发送一个信号。条件满足时，信号量会设为 1（线程 A 还没有运行）或者唤醒休眠的线程 A（A 已经运行）。

### 生产者/消费者问题

信号量可以解决生产者/消费者问题。使用两个信号量 empty、full 可以控制生产和消费。如果要引入一个共享变量，那么必须再使用一个互斥锁，防止出现竞争问题。

生产者/消费者问题本质上就是一个有界缓冲区问题（bounded buffer）。

### 读写锁

读与读不互斥，写与读和写都互斥。直接看书上代码，略。

### 哲学家吃饭问题

可能有死锁的写法：

```c
void getforks() {
    sem_wait(forks[left(p)]);
    sem_wait(forks[right(p)]);
}
void putforks() {
    sem_post(forks[left(p)]);
    sem_post(forks[right(p)]);
}
```

至少一个哲学家的获取锁的顺序要与其他人不同，以**打破环**：

```c
void getforks() {
    if (p == 4) {
        sem_wait(forks[right(p)]);
        sem_wait(forks[left(p)]);
    } else {
        sem_wait(forks[left(p)]);
        sem_wait(forks[right(p)]);
    }
}
```

### 如何实现信号量

很简单，使用锁和条件变量就可以实现一个信号量。条件变量的目的是实现“唤醒”与“休眠”，而同时需要一个共享变量来记录当前休眠的线程数，所以还需要一个锁。
![-w609](media/15696405470407/15730411663237.jpg)

## 32. 常见的并发问题

- 非死锁：
- 违反原子性：比如，访问共享变量前没有加锁。违反了*原子性假设*
- 违反顺序：线程执行的顺序是不确定的，不能依赖于线程执行的顺序
- 死锁

非死锁问题可以通过恰当使用锁或者条件变量来解决。

产生死锁的四个条件：[第六章：死锁](mweblib://15584297498040)

- 互斥
- 占有且等待
- 不可抢占
- 环路等待

## 33. 基于事件的并发

这里的“并发”说的都是指在**一个进程**里实现并发。以前通过线程实现，这里讨论如何不使用线程实现并发。

基于事件的并发其实就是 I/O 多路复用。

### Event Loop

> 为什么要使用事件而不是线程来实现并发？一是管理多线程的并发比较麻烦，二是多线程场景下**程序对于线程的调度时机是不可控的**，由 OS 完成；而**基于事件的方式可以给程序完整的控制调度的能力**，当然缺点就是随之而来的复杂性与整合现代操作系统的某些方面的困难性（如分页）。
>
> 对于一个进程而言，采用线程或事件实现并发并没有明确的优劣之分，要结合具体的应用场景进行选择。

如何构建一个不基于多线程的并发框架？基本思路是使用事件循环（Event Loop），这就是“基于事件的并发”。很简单，就是等待某个*事件*发生，然后根据事件*类型*执行对应的*操作*（比如 I/O、调度其他事件等）。经典的例子就是 node.js。

事件循环的伪码很简单，如下所示：

```js
while (1) {
  events = getEvents();
  for (e in events) processEvnet(e); // 交给 event handler 处理
}
```

事件循环就是一个无限循环：每次从事件队列 events 中取出一个事件 e，交给一个事件处理器 event handler 去处理。由于每次 event handler 处理事件的时候整个系统只有这一个程序在运行，因此*选择下一个要运行的事件 e* 就等同于*调度（schedule）*。这种基于事件的并发可以完整地控制调度过程。

### select()、poll()

事件循环的一个关键问题是“如何接收事件”，即 `getEvents()` 如何实现。select() 或者 poll() 系统调用就给线程提供了接受事件的途径。具体描述可见[I/O 多路复用技术（multiplexing）](mweblib://15709468458672)。

> poll 的含义就是“轮询”

对比上面事件循环的伪码，与 select 使用的伪码：

```c
{
    select(socket); // 第一次 select
    while(1)
    {
        sockets = select(); // 无限调用 select
        for(socket in sockets)
        {
            if(can_read(socket))
            {
                read(socket, buffer);
                process(buffer);
            }
        }
    }
}
```

### Event handler 的问题：可能发起阻塞系统调用

> 这主要说的是 event handler 内部，如果发起某个可能阻塞的系统调用，那么整个事件循环都会阻塞，影响表现。

比如基于事件的服务器，在接收到客户端请求时，需要调用 open() 打开文件，读取到文件内容后再返回客户端。open 和 read 调用都是 I/O 请求，可能会阻塞很长时间，在这段时间里 CPU 是浪费的。

基于线程的方法能够避免长时间的阻塞：当一个线程发起 I/O 请求时，它会被挂起，其他线程可以继续运行；当 I/O 完成的时候再继续运行这个线程。见上文“以 open() 系统调用为例”。

但是基于事件的方法则不行：这是单线程的模式，线程里运行着事件循环。一旦某个事件处理器发出一个系统调用导致了阻塞，那么整个线程都会阻塞直到系统调用返回。

解决这个问题的方法很简单：在基于事件的系统里，不允许发出会造成阻塞的系统调用。但是有没有更好的办法？

### 解决办法：异步 I/O

为了克服上述限制，操作系统提供了异步 I/O（asynchronous I/O）接口。当程序调用接口发出 I/O 请求之后，接口会立即将控制权返回给调用者，不需要等待 I/O 结束。异步 I/O 提供了一系列接口，用来判断不同的 I/O 请求是否完成。

操作系统提供了 `AIO control block` 结构体与相关的 API：

- `int aio_read(struct aiocb * aiocbp)`：发出 I/O 请求，如果成功则立即返回
- `int aio_error(const struct aiocb * aiocbp)`：检测 `aiocbp` 代表的 I/O 请求是否成功，如果成功返回 0，否则返回 EINPROGRESS

这里还存在一个问题：程序需要不停的轮询操作系统以判断一个 I/O 是否完成了，这在 I/O 请求很多的时候开销很大。操作系统提供了一种基于**中断**的实现：当一个 I/O 完成的时候，使用 UNIX signals 通知应用程序，signals 会中断程序当前的操作，转去执行程序的 **signal handler**，结束后再返回程序中断的地方继续执行。这种方法和进程发出 `open()` / `read()` 等系统调用时会被挂起、然后等硬件完成时再发出 I/O 中断是一样的。

如果没有异步 I/O，不可能实现一个基于事件的并发方法。

### 附：Unix Signals

Unix signals 会中断程序当前的操作，转去执行程序的 **signal handler**，结束后再返回程序中断的地方继续执行。每个 signal 都有一个名字，比如 HUP(hang up)、INT(interrupt)、SEGV(segmentation violation)。

信号可以由操作系统发送，比如当程序发生段错误（如下标越界）时，OS 会发送一个 SIGSEGV 信号。如果程序配置了这个信号的 handler，那么处理这种错误（比如 debug），否则会执行默认行为，SEGV 的默认行为是杀死进程。

在程序中使用 `signal(signal_name, handler)` 注册 signal handler：

```c
void handle(int arg) {
    printf("stop wakin’ me up...\n");
}

int main(int argc, char * argv[]) {
    signal(SIGHUP, handle);
    while (1) ; // doin’ nothin’ except catchin’ some sigs
    return 0;
}
```

### 异步 I/O 的问题：状态管理

程序状态（program state）包括了程序当前的变量、参数等。对于基于线程的方法，当它从 I/O 系统调用中返回的时候，程序状态就保存在线程自己的栈上（包括 I/O 返回的参数），可以直接访问：

```c
int rc = read(fd, buffer, size); // read 系统调用返回时，将信息保存在 fd 变量上，而这个变量存在栈上
rc = write(sd, buffer, size); // write 系统调用返回时，将信息保存在 sd 变量上，sd 也存在栈上
```

但是对于基于事件的方法来说，情况有点不一样了。比如程序通过 `aio_error()` 轮询 I/O 是否结束，当这个调用返回 read 成功的时候，程序应该去哪儿找对应的变量？或者说，这些变量保存在哪里呢？

> 有人可能会有一个问题：为什么不能像调用 `read()` 一样，直接给 `aio_error()` 传递一个变量来保存 I/O 的读取结果呢？
> 这是因为在基于线程的方法中，当一个线程发出 I/O 调用时，它会被挂起，OS 会调度其他的线程。当 I/O 结束时，硬件发出 I/O 中断，OS 会解析返回值并保存在线程的栈上，然后再运行线程。
> 而基于事件的方法中，I/O 和程序是异步的。当程序发出 I/O 调用后，它不需要等待 I/O 返回，可以执行其他的操作。也就是说它不会被挂起，所以当 I/O 结束的时候，OS 无法将 I/O 的读取结果保存在程序的栈上，因为这时候 OS 并不知道程序运行到了哪一步，也不知道传递给 `aio_error()` 的参数在栈上的哪个位置。
>
> 我还有一个问题：为什么上面的 signal handler 可以接收 `args` 参数？
> 我的猜想：通过 signals 中断转去执行 signal handler 的时候，OS 可以直接把参数放在栈顶。因为这时执行的一定是 handler 的第一行，栈顶自然也就应该是 handler 的参数 args。

解决方案是一个旧的程序语言结构 **continuation**，其思想是：将事件所需的信息保存在一个数据结构里；当事件发生的时候，在这个数据结构里查找信息并处理事件。

比如在网络服务器上，就是使用哈希表记录 socket descriptor(sd)，通过 file descriptor(fd) 索引。当 I/O 完成时，event handler 会使用 fd 在 continuation（即哈希表）中查找得到其对应的已就绪的 socket descriptor，这时服务器就可以往 socket 中写入数据了。

### 结语

事件还存在的问题：

1. 多 CPU 的情况下会有多个 event handlers 并行运行，可能发生并发问题，违背了 event-based approach 的主要目的就是完整控制程序(handlers)的运行顺序。
2. 尽管基于事件的方法显式地避免了阻塞（通过异步 I/O），但是无法避免隐式阻塞。比如发生缺页中断的时候，程序会被阻塞直到页面加载，这可能影响性能。
3. 基于事件的代码在某些例程改变的时候就很难维护了。比如某个非阻塞例程变成阻塞例程的时候，event handler 就必须改写了。程序员必须谨慎地检查每个调用的 API，确保其不是阻塞的。
4. 异步磁盘 I/O 在大多数平台可用，只需要简单的 `select()`，但是异步网络 I/O 还没有一个简单统一的接口，通常需要结合 `select()` 和 `AIO`。

### 附：Map-Reduce 方法

实现并发又避免了多线程的复杂性如锁、条件变量等。

# ---
